# -*- coding: utf-8 -*-
"""techtern_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FmfmvhcZ2o6R01msiPI5IW7-GVTcXLNc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder, StandardScaler

url = "https://raw.githubusercontent.com/SushiApril/Techtern-insight/rebuild-site-with-flask/jobs.csv"
df = pd.read_csv(url)
df.head()

# converting hourly rate to yearly
def extract_min_max(salary):

    if pd.isna(salary) or salary is None:
        return None, None
    clean_salary = salary.replace('$', '').replace(',', '').split(' (')[0].replace('\xa0', ' ')
    try:
      if 'Per Hour' in clean_salary:
          min_val, max_val = [float(val) for val in clean_salary.split(' Per Hour')[0].split(' - ')]
          # convert hourly to yearly (using 40 hours/week and 50 weeks/year)
          min_val, max_val = [val * 40 * 50 for val in (min_val, max_val)]
      elif 'K' in clean_salary:
          min_val, max_val = [float(val.split(' ')[0].replace('K', '')) * 1000 for val in clean_salary.split(' - ')]
    except:
      return None, None
    return min_val, max_val

min_lambda = lambda x: extract_min_max(x)[0] if not pd.isna(x) and extract_min_max(x)[0] is not None else None
max_lambda = lambda x: extract_min_max(x)[1] if not pd.isna(x) and extract_min_max(x)[1] is not None else None

df['min_salary'] = df['salary'].apply(min_lambda)
df['max_salary'] = df['salary'].apply(max_lambda)
df['avg_salary'] = (df['min_salary'] + df['max_salary']) / 2

df.head()

df.drop(columns=['salary'], inplace=True)
df.head()

df = df.dropna(subset=['name-of-company', 'location', 'name-of-job', 'avg_salary'])

# One-hot encode categorical columns
encoder = OneHotEncoder(drop='first')
encoded_features = encoder.fit_transform(df[['name-of-company', 'location', 'name-of-job']])
encoded_df = pd.DataFrame(encoded_features.toarray(), columns=encoder.get_feature_names_out(['name-of-company', 'location', 'name-of-job']))
# concatenate the original dataframe with the encoded dataframe
df = pd.concat([df, encoded_df], axis=1)

# drop the original categorical columns as they've been encoded
df = df.drop(columns=['name-of-company', 'location', 'name-of-job'])

"""#Simple Linear Regression"""

# splitting the data into training and test sets
X = df.drop(columns='avg_salary')
y = df['avg_salary']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train.drop(columns=['application-link'])
X_test = X_test.drop(columns=['application-link'])

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# creating and training the linear regression model
model = LinearRegression()

# drop rows in the training set where any of the column has NaN values
nan_rows = np.any(np.isnan(X_train_scaled), axis=1)
X_train_scaled_clean = X_train_scaled[~nan_rows]
y_train_clean = y_train[~nan_rows]

# drop rows in the test set where any of the column has NaN values
nan_rows_test = np.any(np.isnan(X_test_scaled), axis=1)
X_test_scaled_clean = X_test_scaled[~nan_rows_test]
y_test_clean = y_test[~nan_rows_test]

# fit the model using the cleaned data
model.fit(X_train_scaled_clean, y_train_clean)

nan_rows_test = np.any(np.isnan(X_test_scaled), axis=1)
X_test_scaled_clean = X_test_scaled[~nan_rows_test]
y_test_clean = y_test[~nan_rows_test]

# make predictions using the cleaned test data
y_pred = model.predict(X_test_scaled_clean)

from sklearn.metrics import r2_score
# calculating the RMSE (Root Mean Squared Error), R^2
rmse = mean_squared_error(y_test_clean, y_pred, squared=False)
print(f'Linear Regression RMSE: {rmse}')
print(f'Linear Regression R^2: {r2_score(y_test_clean, y_pred)}')

residuals = y_test_clean - y_pred
plt.scatter(y_pred, residuals, alpha=0.5)
plt.title('Residual Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.axhline(y=0, color='red')
plt.show()

plt.scatter(y_test_clean, y_pred, alpha=0.5)
plt.title('Actual vs. Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.plot([min(y_test_clean), max(y_test_clean)], [min(y_test_clean), max(y_test_clean)], color='red')  # y=x line
plt.show()

"""#Lasso Regression"""

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score

# create a Lasso regressor object
alpha_value = 1.0  # This is a hyperparameter. You might need to tune it.
lasso = Lasso(alpha=alpha_value)

# fit the model
lasso.fit(X_train_scaled_clean, y_train_clean)

y_pred_lasso = lasso.predict(X_test_scaled_clean)

# calculate RMSE and R^2
rmse_lasso = mean_squared_error(y_test_clean, y_pred_lasso, squared=False)
r2_lasso = r2_score(y_test_clean, y_pred_lasso)

print(f"Lasso Regression RMSE: {rmse_lasso}")
print(f"Lasso Regression R^2: {r2_lasso}")

residuals = y_test_clean - y_pred_lasso
plt.scatter(y_pred_lasso, residuals, alpha=0.5)
plt.title('Residual Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.axhline(y=0, color='red')
plt.show()

plt.scatter(y_test_clean, y_pred_lasso, alpha=0.5)
plt.title('Actual vs. Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.plot([min(y_test_clean), max(y_test_clean)], [min(y_test_clean), max(y_test_clean)], color='red')  # y=x line
plt.show()

"""#Random Forset"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# reandom forest object
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

#fit the model
rf_regressor.fit(X_train_scaled_clean, y_train_clean)

y_pred_rf = rf_regressor.predict(X_test_scaled_clean)

# calculate RMSE and R^2 for random forest
rf_rmse = mean_squared_error(y_test_clean, y_pred_rf, squared=False)
rf_r2 = r2_score(y_test_clean, y_pred_rf)
print(f'Random Forest R^2: {rf_r2}')
print(f'Random Forest RMSE: {rf_rmse}')

residuals = y_test_clean - y_pred_rf
plt.scatter(y_pred_rf, residuals, alpha=0.5)
plt.title('Residual Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.axhline(y=0, color='red')
plt.show()

plt.scatter(y_test_clean, y_pred_rf, alpha=0.5)
plt.title('Actual vs. Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.plot([min(y_test_clean), max(y_test_clean)], [min(y_test_clean), max(y_test_clean)], color='red')  # y=x line
plt.show()